Thank you, Regina. Good afternoon, everyone, and thank you for joining us. With me on today's call are Jayshree Ullal, Arista Networks Chairperson and Chief Executive Officer, and Chantelle Rideup, Arista's Chief Financial Officer. This afternoon, Arista Networks issued a press release announcing the results for its fiscal first quarter ending March 31st, 2025. If you want a copy of this release, you can access it online at our website. During the course of this conference call, Arista Networks Management will make forward-looking statements, including those relating to our financial outlook for the second quarter of the 2025 fiscal year, longer-term business model, and financial outlook for the 2025 and beyond. our total addressable market and strategy for addressing these market opportunities, including AI, customer demand trends, tariffs and trade restrictions, supply chain constraints, component costs, manufacturing output, inventory management, and inflationary pressures on our business, lead times, product innovation, working capital optimization, and the benefits of acquisitions, which are subject to the risks and uncertainties that we discuss in detail in our documents filed with the SEC, specifically in our most recent Form 10-Q and Form 10-K. and which could cause actual results to differ materially from those anticipated by these statements. These forward-looking statements apply as of today, and you should not rely on them as representing our views in the future. We undertake no obligation to update these statements after this call. This analysis of our Q1 results and our guidance for Q2 2025 is based on non-GAAP and excludes all non-cash stock-based compensation impacts, certain acquisition required charges, and other non-recurring items. A full reconciliation of our selected GAAP to non-GAAP results is provided in our earnings release. With that, I will turn the call over to Jayshree. Thank you, Rudy, and thanks, everyone, for joining us this afternoon for our first quarter 2025 earnings call. I'm sorry, I have a bit of a cold, so if I sound nasal, please excuse me. Wow, what a year it's already been with all the seesawing of tariffs. We had a good start in Q1 2025 with the momentum of generative AI, data center, cloud, and campus enterprises, where we achieved our first $2 billion quarter, doubling just 11 quarters after our first billion-dollar quarter. Software and service renewals contributed approximately 17.1% of revenue. Our non-GAAP gross margin of 64.1% was influenced by efficient supply chain without tariffs, yet, I might add, and a nice mix of enterprise and cloud customers in the quarter. International contribution for the quarter registered at 20%, with the Americas super strong at 80%. Clearly, Arisa is redefining the future of data-driven networking, working intimately with our top customers as we march on in the evolution of data centers, campus centers, branch centers, and AI centers. Our cloud and AI momentum continues as we remain confident of our 750 million front-end AI goal in 2025. We are progressing well in all four customers and continue to add smaller ones as well. At the GTC event in March of 2025, we heard all about NVIDIA's planned GPU roadmap every 12 to 18 months, and Arista intends to be the premier and preferred scale-out network for all of those GPUs and AI accelerators. Traditional GPUs have their collective communication libraries, or CCL as they're known, that try to discover the underlying network topology using localization techniques. With this accelerated compute approach, the discrepancies between the discovered topology and the one that actually happens can impact AI job completion times. Arista's eBuilding portfolio highlights the accelerated networking approach, bringing that single point of network control and visibility as a differentiation. This makes it extremely crisp to identify and localize performance issues especially as the size of the AI cluster grows to 50,000 and 100,000 XPUs with the Arista AI spine and least network designs. Moving to campus and branch center trends, in today's AI wave, customers can no longer tolerate LAN and WAN silos. The concept of what comprises a user or a device or a site fundamentally changes the building of a branch or campus in 2025. Agentic AI makes us question the very definition of what we might even consider a user. Future campus and branch centers could be centralized or distributed, or they could be dispersed across laptops, smartphones, a house, an airplane, or any other location on the move. Data and applications can be located anywhere and add more dimensions, whether it's a data center or a public cloud or campus. Therefore, Arista's cognitive campus portfolio features our advanced find with power over Ethernet wired lease capabilities, along with a wide range of cost-effective wireless six or seven indoor and outdoor access points for the newer IoT and agentic applications. Our enterprise momentum continues. These initiatives are contributing greatly to customer momentum, and so let me highlight a few customer wins we have achieved. Our first customer win is in the federal sector, which is new to Arista. where Arista secured a strategic net new campus switching deployment with a major civilian agency, displacing a longstanding incumbent. Arista delivered the digital transformation for their return to work, return to office policy with resilient campus designs featuring Wi-Fi readiness and deep integration of Cloud Vision for real-time telemetry, automation, and compliance. This mission-critical high-performance deployment positions us for a broader entry in the federal market. Our next win comes from a high-tech sector where Arista expanded its partnership with one of our business development partners following years of engagement. The customer made a strategic decision to transition key parts of its data center and campus networks to Arista, marking our first wins with them in both areas. Arista's consistent architecture across platforms based on our single and superior extensible operating system was a key differentiator. The rollout spans key platforms all managed through Cloud Vision for automation, compliance, and visibility. With successful Wi-Fi evaluations underway, Arista is poised to complete and deliver client to cloud experience. And our final win comes from a Web 3.0 infrastructure space where Arista was selected to support the build out of a decentralized global backbone for distributed systems and blockchain networks. As the project shifted from metro expansion to upgrading core network capacity, Arista's 7280R3 routing at scale, paired with our 7130 series for ultra-low latency edge, formed the new 100 gigabit WAN spine. With edge processing, this delivers advanced security, programmable traffic filtering, all at scale. It marks a strategic pivot towards high performance and reliable routing where legacy routers fall short. You can see that all these three wins across three sectors underscore Arista's growing momentum as customers modernize their networks in response to legacy complexity, vendor consolidation, and mission-critical demands. As I wrap up, I want to share our conscious focus in cultivating our next generation of leaders. We have been fortunate and blessed to have a cohesive team for the past 15 years, but sometimes we must accept changes. Financial success gives people choices, especially our Arista executives. Some may retire, while others may elect to pursue new ventures. In the next phase of Arista 2.0 leadership, it's important to know that some things remain unchanged and steadfast. Our engineering brains and bench strength, for example, with Andy, Ken, Hugh, as well as new Vice President of Software, Siva Narayanan, and new Vice President of Hardware Engineering, Alex Rose, continue to be stronger than ever. You know Arista's reputation for A-plus engineering team, and this is a renowned hallmark in the Valley. With the summer leave of absence of John McCool, Mike Kappas has been appointed as our new VP of Manufacturing. Mike has been with us over 12 years and is doing just a fantastic job navigating the supply chain and uncertainties of tariffs. On the enterprise sales side, our dynamic duo, Chief Customer Officer Ashwin and Chief Sales Officer Chris, are driving success globally, expanding campus, data center, and AI footprints with increasing market share. Chris and Ashwin have brought changes in the sales and SE leadership team internationally, both in Asia and in Europe. For the America sales, we have promoted a 16-year Arista veteran, Chris Bellmer, to Senior Vice President. Chris embodies the combination of customer empathy, product expertise, and always doing the right thing. You can see common traits across all these executives with incredible and tenured talent, strong cultural synergies, and a mission to delight customers. We are executing very well, and we aim for $10 billion revenue and beyond sooner than we previously expected. Speaking of Arista 2.0 executives, over to you, our CFO, Chantel. who epitomizes our core values at Arista and recently expanded her responsibilities to include legal, IT, and CISO functions. Thank you, Jayshree. I am excited to extend my scope to cover these key functions. With that, there are a few organizational announcements to make regarding these teams. Our newly named leaders include Sandra Yuen, promoted to be our VP of Information Technology, Jason Bevis, promoted to be our cybersecurity leader in CISO, and Shawn Christopherson, who tomorrow becomes our general counsel, replacing Mark Taxe, who has decided after many dedicated and successful years at Arista to try a new adventure. Congratulations to all of you. By promoting proven leaders from within, we are reinforcing our culture of excellence and positioning ourselves for continued success. With that organizational momentum, let's review our financial results. Total revenues in Q1 were $2.005 billion, up 27.6% year over year, and above the upper end of our guidance of 1.93 to 1.97 billion. This year-over-year growth was led by strength in the cloud-tightened vertical and non-cloud performing better than expected. International revenues for the quarter came in at $406 million, or 20.3% of total revenue, up from 16% in the last quarter. This quarter-over-quarter increase reflects normal quarterly volatility and includes the impact of an unusually high contribution from our America's customers in the prior quarter. Gross margin in Q1 was 64.1% above our guidance of approximately 63%. This is down slightly from 64.2% both last quarter and Q1 FY24. The Q1 result above our guidance was driven by a stronger than expected mix of non-cloud revenue and includes a minimal impact from the absorption of applicable tariffs. Operating expenses for the quarter were $327.4 million or 16.3% of revenue down slightly from last quarter at $332.4 million. R&D spending came in at $209.4 million, or 10.4% of revenue, down from $226.1 million last quarter. This reflects a low double-digit year-over-year headcount increase offset by lower new product introduction costs in the period due to timing of prototypes and other costs associated with our next-generation products. Sales and marketing expense was $94.3 million, or 4.7% of revenue, compared to $86.3 million last quarter, with a mid-single-digit growth in headcount versus last year. Our G&A cost came in at $23.7 million, or 1.2% of revenue, up from 1% of revenue in the prior quarter. Income from operations for the quarter was $957.4 million, or 47.8% of revenue. Other income for the quarter was $90.7 million, and our effective tax rate was 21.2%. This resulted in net income for the quarter of $826.2 million, or 41.2% of revenue. Our diluted share number was 1.279 billion shares, resulting in a diluted earnings per share for the quarter of 65 cents, up 30% from the prior year. Note that this reflects our four-to-one stock split in December 2024. Now turning to the balance sheet. Cash equivalents and investments ended the quarter at approximately $8.15 billion. During the quarter, we repurchased $787.1 million of our common stock, our largest repurchase quarterly or annually in Arista's history. In April, we repurchased an additional $100 million for a total of $887.1 million at an average price of $88.97 per share. To date, we have repurchased 13.3M shares at an average price of $87.55 with $34M remaining in the existing $1.2B board authorization. In May 2025, our board of directors authorized a new $1.5B stock repurchase program, which commences after we have completed repurchases under our existing $1.2B authorization. The actual timing and amount of future repurchases will be dependent on market and business conditions, stock price, and other factors. Now turning to operating cash performance for the first quarter, we generated approximately $641.7 million of cash from operations in the period, reflecting a growth of 24.9% compared to Q1 fiscal year 24. DSOs came in at 64 days, up from 54 days in Q4, driven by billing linearity. Inventory turns were 1.4 flat to last quarter. Inventory increased to approximately $2 billion in the quarter, up from 1.8 billion in the prior period, reflecting an increase in finished goods. This is an intentional action regarding both tariffs and in the support of ramping new products. Our purchase commitments at the end of the quarter were $3.5 billion, up from 3.1 billion at the end of Q4. This was driven by a continued investment in chips, as well as an increase in buffers due to the tariff uncertainty. From a cash flow perspective, we will continue to optimize our working capital investments with some expected variability in inventory due to the timing of receipts on purchase commitments. Our total deferred revenue balance was $3.1 billion, up from $2.8 billion in Q4 fiscal year 24. The majority of the deferred revenue balance is services related and directly linked to the timing and term of service contracts, which can vary on a quarter by quarter basis. Our product deferred revenue balance increased by approximately $219 million versus last quarter. We remain in a period of ramping our new products, winning new customers, and expanding new use cases. These trends have resulted in increased customer specific acceptance clauses and an increase in the volatility of our product deferred revenue balances. As mentioned in prior quarters, the deferred balance can move significantly on a quarterly basis, independent of underlying business drivers. This may be further amplified in 2025 due to the uncertainty around tariffs throughout the fiscal year and the resulting buying patterns of our customers. Accounts payable days were 49 days down from 51 days in Q4, reflecting the timing of inventory receipts and payments. Capital expenditures for the quarter were $32 million. In October, we began our initial construction work to build expanded facilities in Santa Clara. And we expect to incur approximately $100 million in capex during fiscal year 25 for this project. Now turning to our outlook. Given the nature of the current macroeconomic environment, we will start with the second quarter and then move to fiscal year 25. As is demonstrated by our Q1 results, we have seen good momentum at the beginning of fiscal year 25. As Jayshree highlighted, there are opportunities across all three customer sectors, inclusive of GenAI, data center, cloud, and campus enterprises. that combined with favorable mix has allowed for better than expected margin outcomes building on this momentum our guidance for the second quarter is as follows revenues of approximately 2.1 billion dollars this reflects stronger seasonality in q2 than prior year trends and anticipate the outcome of the tariff uncertainty gross margin of approximately 63 percent including the absorption of known tariffs for the q2 period and operating margin at approximately 46 percent Our effective tax rate is expected to be approximately 21.5%, with approximately 1.272 billion diluted shares. Now turning to the full fiscal year 25. Despite the macro uncertainty, we remain confident in the demand from our cloud enterprise and providers' customers. As is in the case of many other companies, the second half holds significant ambiguity related to the tariff scenarios. Given these unknowns, our guidance for FY25 currently remains unchanged, despite the strong results and guidance we are reporting today. We believe we can deliver results in the gross margin range of 60 to 62%, even as we anticipate known possible tariff scenarios within Q3 and Q4. This is possible through a mix of supply chain optimization, tariff absorption, and potential price increases, if required. As we move through the quarters, we will continue to revisit the annual guide, hopefully in an environment unconstrained by tariff uncertainty. Energized by the current momentum, we continue to focus on operational discipline and innovation, ensuring we deliver strong outcomes for customers and shareholders. Now back over to you, Rudy, for Q&A. Thanks, Chantel. Just a quick clarification before we go into Q&A. Jayshree meant we were reiterating our back-end goal of $715 million, not front-end AI. With that, we will now move to the Q&A portion of the Arista earnings call. To allow for greater participation, I'd like to request that everyone please limit themselves to a single question. Thank you for your understanding. Regina, please take it away. We will now begin the Q&A portion of the Arista earnings call. In order to ask a question during this time, simply press star then the number one on your telephone keypad. If you would like to withdraw your question, press star and the number one again. We ask that you pick up your handset before asking questions in order to ensure optimal sound quality. Our first question comes from the line of David Vogt with UBS. Please go ahead. All right. Thanks, guys, for taking my question. So maybe Jayshree and Chantal, can you maybe just dive a little bit deeper on how you're thinking about the impact of tariffs? Obviously, product deferred revenue is up sequentially. We recognize that it's uncertain going into the second half of the year. So maybe from a top line perspective, how are you thinking about what your customers are telling you? What can you share with us? And just give us a sense for, you know, how you thought about it relative to where tariffs are today versus what maybe is proposed by the administration. So I assume that it's kind of the status quo of where we are today is kind of underpinning your outlook. But any clarity would be helpful. Thank you. Sure, David. I'll start and maybe Chantal can clarify. You know, when we began this adventure on tariffs, We were actually trying to get out of Mexico as fast as we could because the expectation was Mexico would have a tariff in Q1. As the news came about, you know, we literally find ourselves in the middle of an ocean trying to figure out which country to go to because the tariffs, as you know, the reciprocal tariffs are much higher in some of the Asia countries. So we're grateful for the measured approach that we do not have to deal mostly with any of these tariffs until July 9th. We are absorbing whatever tariffs we do have to deal with from China and other things. But should that change, we expect it to have some effect that Shantel alluded to in our gross margins that we have taken into consideration for the year. And some we will absorb and some we may potentially have to pass to our customers. But we don't know what we don't know. So we can just go at this one quarter at a time. Yeah, I think the only thing I would add, so I think, in regard to the top line, Jayshree, completely, we saw the momentum in Q1. You saw our guide in Q2, which is, I think, linearity-wise, a stronger Q2 than usual. We're holding the year. That's not because of our demand outlook. It's because of the fact we just want to have any surprises after the pause. So that's why we'll take it quarter by quarter. On the tariff side, in regard to gross margin, if you were to take those commentaries, that puts the range of growth of tariff impact to be one to one and a half points at the top layer with no mitigation. So that kind of bookends the impact we expect. Worst case scenario without any mitigation to J Street Point, there may be a point where we have to have the price increases, but we're looking to mitigate through absorption and tariff and supply chain fungibility. And so from that perspective, we tried to bookend the impact. We see momentum on the top line and we'll update quarter by quarter. Great. Thanks, Jayshree. Thanks, Chantel. Sure, David. Our next question comes from the line of Amit Daryanani with Evercore. Please go ahead. Thanks for taking my question. Jayashree, I think there's been a fair amount of noise and speculation on the four or five backend AI customers that you have and sort of the different things they're exploring. Just from your perspective, can you talk about how are these customers and aggregates progressing for the backup RAMs? And is that one-to-one ratio for the frontend and backend still impacting your perspective? Yeah. So first, let me start with the four customers. All of them are progressing well. One of them is still new to us. They've been in InfiniBand for a long time, so they'll be small. I would say two of them are heading towards 50,000 GPU deployments by end of the year. Maybe they'll be at 100, but I can be most certainly sure of 50K heading to 100K. And then the other one's also in production. So I had talked about all four going into production. Three are already in production. The fourth one is well underway. So I think our backend number of 750 million, I'm feeling good. I'm feeling confident. And if you knew more or less about tariffs, maybe I'd feel more confident. On the frontend ratios, yeah, we've said it's generally one-to-one. It's getting harder and harder to measure frontend and backend. Maybe we look at this whole AI cluster differently next year. But I think one-to-one is still a good ratio. It varies. Some of them just build a cluster and don't worry about the frontend, and others worry about it entirely holistically. So it does vary, but I think the one-to-one is still a good ratio. Thank you. Thanks, Amit. Our next question comes from the line of Atif Malik with Citi. Please go ahead. Hi, thank you for taking my question. Chantel, you talked about 2Q being seasonally stronger. Can you give us a bit more color? Are you seeing any pull forwards because of the concern on tariffs? Yeah, I think that I wouldn't call it significant or material, but enough in the sense that we want it to be pretty clear on that top-end guide. So yes, some, but I wouldn't say significant. Thank you. Our next question comes from the line of Aaron Rickers with Wells Fargo. Please go ahead. Yeah, thanks for taking the question, and congrats on the results. The product deferred revenue balance from $990 million up to like $1.2 billion, I can appreciate the timing of that and kind of giving the tariff backdrop somewhat difficult. But I'm curious of how we should think about that from a forward perspective. And in particular, is it tied to kind of the distributed Etherlink platforms or the 51.2T silicon? Are we still kind of early innings and seeing those actually materialize from a production deployment perspective? And that that might be tied to that product deferred or any kind of color around that would be great. Thank you. Right, Aaron. If you remember, we had a similar phenomena way back in 2016 when we had 100 gig deployments in the cloud that may be testing everybody's memory. But I think there's a similar phenomena going on here with all our EtherLink platforms. You mentioned the distributed EtherLink, but it also includes the 7800 spine and the EtherLink 51T standalone switches. we're experiencing a lot of interest in these products, but everybody's new to AI. They've never really put together a network design, you know, for four rail or eight rail, or how does it connect into the GPUs? And what is the NIC attachment? What is the accessories in terms of cables or optics that connect? So, you know, this movement from trials to production causes us to bring a whole ecosystem together for the first time. So you can see that's why It's impacting our deferred revenue some, and this kind of timeframe can easily be 12 to 18 months. In the cloud days, it used to be more like six months because it wasn't as new. Thank you. Sure. Our next question comes from the line of Ben Reitzis with Milius Research. Please go ahead. Hey, guys. Thank you so much for the question. I wanted to just on the second half, you know, in order to, be in 15% range or 15 to 17, you know, you have to kind of get into the single digits there. So just wondering, you know, with the cloud providers that you serve, I, you know, when they get the stuff from NVIDIA, it's not, I thought it was non-cancelable, et cetera. And there's pretty good visibility on what they're going to do, you know, with either XPUs and GPUs. you know, because this stuff has kind of a long lead time and the orders are already made. So I'm just a little confused as to why you really don't know so much about the second half, at least on the top line, given these orders are non-cancellable from so many of the hyperscalers that you deal with. Thank you. Yeah, I think, thank you for the question. I'll start and then maybe Jason might have commentary. I think it's more from the perspective of not having to update the guide for every permutation and combination. I think we prefer to update the guide once we have an answer on the pause then. So it's not that we don't have a view. It's more we just want to update the guide once with all the known variables changed with some significance. Jayshree, anything you want to add? Yeah, no, listen, I think you have a right to be confused. We're also confused about the tariffs. If there were no tariffs, we'd be even more optimistic about the second half. So we're being careful, measured, because we don't know. what the tariffs will go. We don't know if the country will go into a recession, but specific to your comment on visibility and enthusiasm and momentum, I think you've heard it from us. We're seeing it on the cloud. We're seeing it on AI. We're seeing it on campus enterprises. So if there were no other variables, we'd be even more bullish. Thank you, Jayshree. Sure, Ben. Our next question comes from the line of Sonic Chatterjee with JP Morgan. Please go ahead. Hi, thanks for taking my question. Just maybe if I can go back to the four tier ones that you're working with on the AI backend and the progress that you updated on that front. Are these customers now giving you more visibility just given the tariff landscape and that you would need to sort of build inventory for some of the finished goods? And can you just update us how they're handling the situation on that front? And particularly then, as you think about, I think the investor focus is a lot about sort of 2026 and potential sort of changes in the CapEx landscape from these customers at that point. Are you getting any forward visibility from them, any sort of early signs for 2026 from these customers? Thank you. Right, right, Samik, yeah. So we definitely have all the visibility in the world for this year, and we're feeling good. We're getting unofficial visibility because they all know our lead times are tied to some fairly long lead times from our partners and suppliers. So I would say 2026 is looking good. And based on our execution of 2025 and plans we're putting together, we should have a great year in 2026 as well for AI clusters specifically. Our next question comes from the line of Carl Ackerman with BNP Paribas. Please go ahead. Yes, thank you, Jayshree. How do you see the general cadence of hyperscalers deploying 800 gig switch ports this year? I ask because I believe your Etherlink family of switches became generally available in late 2024. And I'm wondering if these switches relate to your growth of deferred revenue the last couple of quarters. Thank you. Yeah, that's a good question. You may remember, Carl, that I alluded to this earlier in 2024. The majority of our EI trials were on 400 gig at that time. So you're right to observe that with our EtherLink portfolio really getting introduced in the second half of 24 that a lot of our 800 gig activity has picked up in 2025, some of which will be reflected in shipments and some of it which will be part of our deferred. So it's a good observation and an accurate one that this is the year of 800 like last year was the year of 400. Our next question comes from the line of Michael Ng with Goldman Sachs. Please go ahead. Hi, good afternoon. Thank you for the question. Jayshree, I was wondering if you could just expand upon your comments about your confidence in achieving the $10 billion midterm revenue target a little bit sooner than previously expected. And, you know, how do you kind of balance that, you know, longer term or midterm optimism with some of the choppiness that we see now? Thank you. Michael, I knew somebody would ask that question. I'm surprised it took so long. So those of you who remember the analyst day in November 2023, I had said it took nine years to get our first 5 billion and I thought to want to go away, which is really looking for the update on Whitebox. I know you've talked about this quite a bit in the past. It seems as if it's maybe come back. And if you could help us understand how you split your business with Whitebox competitors and how you see that shifting, if at all. Thank you. Sure. First, I want to say, which I've always said, that Whitebox is not new. It's been with us since the beginning of time. In fact, When Arista got started, a couple of our customers had already implemented internally various implementations of Whitebox. So there is a class of customers who will make the investments in engineering and operations to build their own network and manage it. And it's a very different business model. It operates typically at 10% gross margins. I don't think you want Arista to go there. And it's very hardware centric and doesn't require the rich software foundation and investments that we've made. So first, I'll start by saying we will always and will continue to coexist with Whitebox. There are times, and you'll notice this too, that because Arista builds some very superior hardware, that even if they don't use our EOS, they like to have our blue box, as I often call it, the Arista hardware, that's engineered much better than any others, a more open OS like Sonic or FBOS, or at least the attributes of running both EOS and an open source networking system. So I think we view this as a natural part of selection in a customer base where if it's a simple use case, they're going to use something cost effective. But if it's a really complex use case like the AI spine or roles that require and demand more mission critical features, it just always plays a far bigger role in premium highly scalable, highly valued software and hardware combinations than we do in a standalone white box. So we'll remain co-existent peacefully and we're not in any way threatened by it. In fact, I would say we work with our customers to make sure as they're building permutations and combinations of white box that we can work with that and build the right complement to that with our EtherLink portfolio. Thank you. Our next question comes from the line of Antoine Gabin with New Street Research. Please go ahead. Hi, good afternoon. Thank you for letting me ask a question. I'd love to get your latest views around co-packaged optics. NVIDIA introduced its first CPO switches at GTC for scale-out, and I was wondering whether that had any impact on your views regarding CPO adoption in backend AI networks in coming years. No, it's had no impact at very early days. I think you've seen, you know, Arista doesn't build optics, but Arista enables optics, and we've always been at the forefront, especially with Andy Beckleshine and his team of talented tech individuals, that, you know, whether it is pluggable optics with LPO or how we define the OSFP connector for MSAs for 100 gig, 400 gig, you know, it's something we take seriously, and our views on CPOs, it's not a new idea. It's been demonstrated in prototype for, I don't know, 10 to 20 years. The fundamental lack of adoption to date on CPO, it's relatively high failure rates, and it's mostly been in the labs. So what are some of the advantages of CPO? Well, it has a linear interface. It has lower power than DST for long-haul optics. It has a higher channel count. And I think if pluggable optics can achieve some of that in the best of both worlds, then you can overcome that with pluggable optics or even co-packaged copper. So Arista has no religion. We'll do co-packaged copper. We'll do co-packaged optics. We'll do pluggable optics. But it's too early to call this a real production-ready product. It's still in very early experiments and trials. Great. Thank you, Jayshree. Sure. Our next question comes from the line of Mita Marshall with Morgan Stanley. Please go ahead. Great. Thanks. I wanted to kind of ask about, you reiterated the $750 million back end target, but you've kind of had this $1.5 billion kind of AI target for 2025. And just wondering, is achievability of that more dependent on kind of the tariffs given kind of some of the front end spend? Or just how are you thinking about that $1.5 billion number? Thanks. Sure. I think we're aiming for the 750 because it's more measurable. The one and a half is a nice goal, but sometimes we can't tell whether it's AI traffic or cloud traffic. Sorry, I got tariff on my brain. Regarding tariffs, I don't think it'll have a material difference on the 750 million number or the 1.5 billion. We got the demand. So unless we have some real trouble shipping it or customers change their mind, I think we're good with both those targets for the year. Great. Thank you. Sure, my dear. Our next question comes from the line of Matt Nickman with Deutsche Bank. Please go ahead. Hey, thanks so much for taking the question. Can you talk a little bit about what you're seeing on the macro front? And I guess more specifically, how that's affecting spending plans and sales cycles across the different customer sets, whether it's Cloud9, Titans, Enterprise, or even Tier 2 Cloud and some of the service providers, customers. Thank you. Sure. And Chantal, you may also have a view on this. Love to hear that. You know, I've never been a good soothsayer or forecaster of macro trends. Going back to my years at Cisco and now, recessions don't give you a warning. They just happen. And at the moment, we do not see any warning of a recession. In fact, we're seeing the opposite. We're seeing a lot of demand, whether it's people pulling it in for tariffs or just the general excitement of Aristas products. So unless things dramatically change with tariffs, which force a recession, Arista is really experiencing good momentum, and therefore it's very difficult for me to predict a recession unless something outside from a macro happens. Yeah, and I would add to that, you know, if you think about the providers, enterprise, campus specifically, very pleased with our campus, you know, Q1 outlook that we had, results that we had. Campus has shown some strong momentum, longer sales cycles, but continued strong momentum. Enterprise, you know, we continue to win new logos and have great land and expand conversations with our enterprise customers. The providers, the neoclouds, you know, are demonstrated interest and lots of great conversations there. So I think across the spectrum, we haven't seen anything that indicates a recessionary kind of tangent in the conversations. I guess we read the doom and gloom in the news, but we're not feeling it here. Our next question will come from the line of Tal Liani with Bank of America. Please go ahead. Hi, guys. If you go back, can you hear me? Yes, we can. Yes, we can hear you. If you go back a few years, we've seen your customers being nimble and buying ahead of development. For example, you remember when Microsoft responded to The litigation you had with Cisco involved kind of six quarters worth of equipment in four quarters. I remember it happened. And the question is whether the entire market behaves this way now, meaning we know tariffs are coming later in the year, whether the strength you're seeing is the result of early purchases of customers ahead of tariffs in order to save some dollars. The question is twofold. Number one, if it happens, will you ever know about it? Meaning, do you have enough visibility over the deployment schedules to know that they're buying ahead of the demand? And number two is just the answer of what do you think about kind of the question and whether there is, you know, early ordering of equipment. Thanks. Yeah. Now, Ketel, these are very thoughtful questions, and thank you for reminding us. Back then, we were like, you know, three to 500 million a quarter business. They're a lot bigger now. And even if our customers tried to pull it in and get it all by July, we would be unable to supply it. So that would be the first thing. So I'm not seeing the pull-ins that are really material in any fashion. I am seeing a few customers trying to save a dollar here, a buck there to try and ship it before the tariff date, but nothing material. Regarding pull-ins for four to six quarters, Again, our best visibility is near term, and if we saw that kind of behavior, we would see a lot of inventory sitting in our customers, which we don't. In fact, they're scolding us to ship faster than ship more. Got it. Thank you. Thank you. Our next question comes from the line of Sebastian Nagy with William Blair. Please go ahead. Yeah, thank you for taking the question. I mean, I think there's a lot of focus on AI demand, but some of the cloud titans have also been reporting, you know, really robust growth in the non-AI parts of their cloud businesses. So could you maybe comment on what you're seeing on more of that traditional cloud titan demand and whether that's trending ahead of expectations for the year? That's a really good question too, Sebastian. See, I don't know if you remember, again, two years ago, I was very nervous because the entire cloud titans pivoted to AI. and flow down their cloud, now we see a more balanced spend. And while we can't measure how much of this cloud and how much of it is AI, if they're kind of cobbled together, we are seeing, you know, less of a pivot, more of a surgical focus on AI, and then a continued upgrade of their cloud networks as well. So compared to 23, I would say the environment is much more balanced between AI and cloud. Our next question comes from the line of James Fish with Piper Sandler. Please go ahead. Hey, thanks for the question here. Really a follow-up on Simon's one before. What functionality about the blue box actually makes it defensible versus what hyperscalers can kind of self-develop? And then Chantel, on the inventory side, I know you always tell us to look at inventory and purchase commitments, but how are you feeling about where we should expect inventory turns sort of throughout the year and long-term just given the latest wrinkle here on the supply chain. Sure. Do you want to go first, Rishi? Yeah. Let me give you a few attributes of what I call the blue box. And I'm not saying others don't have it, but Arista has built this as a mission. And although we're known for our software, we're just as well known for our hardware. When you look at everything from a form factor of a one RU that we build to a chassis, we've got a tremendous focus on signal integrity, for example. you know, all the way from layer one, multi-layer PCB boards, a focus on quality, a focus on driving distances, a focus on integrating optics for longer distances, a focus on driving MACSEC, et cetera. So that's a big focus. The second is hardware diagnostics. In turn, to the company, we call it AristaBooth. We've got a dedicated team focused on not just the hardware, but the firmware, to make it all possible in terms of troubleshooting. Because when these boards get super complex, you know, you don't even know where the failure is and you're running at high speed, 200 gig 30s. So things are very complex. So the ability to pinpoint and troubleshoot is a big part of what we do. And then there's additional focus on the mechanical, the power supplies, the cooling, all of which translate to better power characteristics, along with our partners and chip vendors. There's a maniacal focus on not just high performance, but low power. So some of the best attributes come from our blue boxes, not only for 48 ports, but all the way up to 576 ports on an AI spine or double that if you're looking for dual capabilities. So well-designed, high-quality hardware is a thing of beauty, but also a thing of complexity that not everyone can do. Yeah, and I think regards to the inventory turns, you know, I think I'm pleased in the progress we've made. We've kind of gone from the range of one turn to 1.4 turns this quarter, even with some of the buffer we've put in for the tariff uncertainty. I think generally your question is forward-looking, what turns are we looking for? We're always looking to make improvements. The only wrinkle we have is this length of duration on the tariff cycle. So we work every month, Mike Kappas and I and his team, to look at the inventory turns and forecasting. We aim to go higher. The only thing I would say as a caveat is what we need to do in the second half, depending on the tariff scenarios. Our next question comes from the line of Ben Bolin with Cleveland Research. Please go ahead. Good afternoon, everyone. Thank you for taking the question. There were some comments you made, Chantal, in the prepared remarks regarding variability and customer acceptance of the product deferred, especially around tariffs. Could you share a little more detail? What does that look like? Does this relate to the absolute size of their deployments, uncertainty in the BOM, just any other considerations we should be aware of? Thanks. Yeah, no, it's a great question because I added that last comment, this go around in the sense of the new unknown of the tariff uncertainty. And there I was just mentioning or, you know, trying to give transparency that there may be quarters as we progress through these tariff scenarios where our customers decide to pull in and where we can accommodate And if it's a new use case or new acceptance clause, that would, you know, impact the deferred revenue. So it's just another item to consider and we'll continue to discuss. But that's the general, you know, just in the sense of adding the uncertainty around that. Yeah. To add to that, Ben, you know, obviously tariffs are an unknown, but I want to go back to that white box, blue box question. We had a customer, again, not material. who said, you know, I can't get these boxes, I can't make them run, I cannot get an AI network. And one of my most technical sales leaders said, hey, we got a chance to build an AI cluster here for a few hundred GPUs. We jumped on it. You know, obviously that customer is small and had been largely using white boxes and is now about to install an AI leaf and an AI spine. And we had to get it to him before the tariff deadline. So it was an example of not material, but how quickly these decisions get made when you have the right product, right performance, right quality, right mission-critical nature, and you can deal with that traffic pattern better than anyone else can. It happens. It's not big because you've got so much commitment in a given quarter from a customer, but when it is, we act with a great deal of nimbleness and agility to do that. Regina, we have time for one last question. Our final question comes from the line of Ryan Coons with Needham and Company. Please go ahead. Great, thanks. Thanks for putting me in. I wanted to ask about the kind of emerging Neo AI opportunities out there. I think there's a general perception that most of them are buying, you know, NVIDIA defined clusters and networking. So I wonder if you could comment on those trends, their interests in moving past InfiniBand and also Are there opportunities developing with some of these folks to kind of multi-source their AI connectivity to different providers? Thanks. Yeah. That's a good question, Ryan. So, in fact, we're seeing more adventurous spirit in the NeoCloud customers because, you know, they want to try alternatives. So, some of them are absolutely trying other AI accelerators, like Lisa and MD and my friends there. Some of them are Absolutely looking at Ethernet, not InfiniBand as a scale out. And that momentum has really shifted in the last year with the Ultra Ethernet Consortium and the spec coming out in May. I just want to give a shout out to that team and what Hugh Holbrook has done. So I think Ethernet's a given, but there's an awful lot of legacy of InfiniBand that will obviously sort itself out. And a new class of AI accelerators we're seeing, you know, more niche players, more internal developments from the Cloud Titans. all of which is mandating more Ethernet. So I think between your two questions, I would say the progress from InfiniBand to Ethernet is faster. The progress from, you know, the renowned, the ones they know and the high-performance GPUs from NVIDIA versus the others is still taking time. Helpful, Jishri. Thank you. Absolutely. Thank you. This concludes Arista Network's first quarter 2025 earnings call. We have posted a presentation that provides additional information on our results, which you can access on the investor section of our website. Thank you for joining us today and for your interest in Arista. Thank you for joining, ladies and gentlemen. This concludes today's call. You may now disconnect.