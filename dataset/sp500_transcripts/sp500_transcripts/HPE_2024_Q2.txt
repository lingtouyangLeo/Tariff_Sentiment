Good afternoon and welcome to the second quarter fiscal 2024 Hewlett Packard Enterprise earnings conference call. My name is Gary and I'll be your conference moderator for today's call. At this time, all participants will be in listen only mode. We will be facilitating a question and answer session towards the end of the conference. Should you need assistance during the call, please signal a conference specialist by pressing the star key followed by zero. As a reminder, this conference is being recorded for replay purposes. I would now like to turn the presentation over to your host for today's call, Jeff Cavall, Head of Investor Relations. Please proceed. Good afternoon. Welcome to our second quarter fiscal 2024 earnings conference call with Antonio Neri, HPE's President and CEO, and Marie Myers, HPE's CFO. Let me remind you that this call is being webcast. A replay of the webcast will be available shortly after the call concludes. We have posted the press release and the slide presentation accompanying the release on our Investor Relations webpage. Elements of the financial information referenced on this call are forward-looking and are based on our best view of the world and our businesses as we see them today. HPE assumes no obligation and does not intend to update any such forward-looking statements. We also note that the financial information discussed on this call reflects estimates based on the information available at this time and could differ materially from the amounts ultimately reported in HPE's quarterly report on Form 10-Q for the fiscal quarter ended April 30th, 2024. For more detailed information, Please see the disclaimers on the earnings materials relating to forward-looking statements that involve risks, uncertainties, and assumptions. Please refer to HPE's SEC filings for a discussion of these risks. For financial information we have expressed on a non-GAAP basis, we have provided reconciliations to the comparable GAAP information on our website. Please refer to the tables and slide presentations accompanying today's earnings release on our website for details. Throughout the call, all revenue growth rates are presented on a year-over-year basis and adjusted to exclude the impact of currency unless otherwise noted. Finally, Antonio and Marie will reference our earnings presentation in their prepared remarks. With that, Antonio. Good afternoon, and thank you for joining us today. HPE delivered a very solid performance in the second quarter, with revenue and non-GAAP diluted net earnings per share exceeding our outlook range. driven by AI systems revenue more than doubling from our first quarter. I am very optimistic about where we are headed. AI demand continues to accelerate, with cumulative AI systems orders reaching $4.6 billion this quarter. We have a robust pipeline in this business, though large AI orders can cause fluctuations during the quarter. We anticipate continued revenue growth driven by increased AI systems demand, continued adoption of HP GreenLake, and ongoing improvement in the traditional infrastructure market, including servers, storage, and networking. Due to our confidence in the second half of fiscal year 2024, we are raising our full year revenue and non-GAAP earnings per share guidance and reiterating free cash flow guidance. Marie will provide more specifics in her remarks. While we focus on translating strong AI customer demand to revenue growth, we continue to drive cost discipline to operate more efficiently and to preserve the ability to make targeted investments, which will sustain our growth into the future. We are being prudent with our spending and reduce operating expenses in the first half as compared to the prior year period. We're also driving business process simplification across the company, including through digitization and automation with AI. Demand for HPE's AI systems is accelerating at a faster pace, and our solid execution enabled us to more than double our AI systems revenue sequentially to over $900 million, helped by supply chain conversion through improved GPU availability. Our lead time to deliver NVIDIA H100 solutions is now between 6 and 12 weeks, depending on order size and complexity. We expect this will provide a lift to our revenues in the second half of the year. Enterprise customer interest in AI is rapidly growing, and our sellers are seeing a higher level of engagement. Enterprise orders now comprise more than 15% of our cumulative AI systems orders, with the number of enterprise AI customers nearly tripling year over year. As these engagements continue to progress from exploration and discovery phase, we anticipate additional acceleration in enterprise AI systems orders through the end of the fiscal year. We're winning in AI for several reasons. Our leadership in AI at scale and across the entire AI lifecycle, from training to fine tuning to inferencing, continues to attract new customers. These customers range from new generative AI model builders, to broader service providers, to sovereign states, to traditional enterprise customers, to large hyperscalers. For example, in partnership with Microsoft, we're extending the Azure AI platform to HPE infrastructure, which provides Microsoft with additional capacity to serve even more customers, including OpenAI. HP has decades of experience in the design, manufacture, and management of air and liquid cool systems, including the data center infrastructure, to reliably deliver the highest levels of computing performance. Customers appreciate our AI at scale expertise and intellectual property, as well as unique liquid cooling manufacturing and services capabilities. As accelerated computing silicon innovation advances, higher power density demand direct liquid cooling technologies. Building direct liquid cooling AI systems is complex and requires manufacturing expertise and infrastructure, including power, cooling, and water. With more than 300 HPE patents in direct liquid cooling, proven expertise, and significant manufacturing capacity for this kind of systems, HPE is well positioned to help customers meet the power demands for current and future accelerated compute silicon designs. Our leadership in AI was once again validated in May, when the latest top 500 list of the world's most powerful supercomputers was released. HP now has four of the top 10 world's fastest supercomputers, all of which are direct liquid cooled. Two of these systems are exoscale supercomputers, with Frontier still the world's fastest and Aurora now breaking the exoscale barrier. I'm also proud that we have built seven of the world's top ten energy-efficient systems, according to the latest Green 500 list. This experience makes us an attractive partner to sovereign states and governments pursuing AI strategies. HPE benefits from a strong ecosystem of AI partners, including NVIDIA. We introduced co-engineered enterprise solutions with NVIDIA last year to streamline the model development process, as well as to enable enterprises to fine-tune large language models with their private data to accelerate inferencing. I'm excited that NVIDIA CEO Jensen Huang will join me at HPE Discover Las Vegas in just two weeks. Together, we will unveil new, exciting, and differentiated innovations that will simplify and accelerate enterprise AI adoption and deployment. Enterprise customers are already responding to our unique AI portfolio. For example, Cubox, a facial and image recognition company in Korea, is developing new generative AI models using HPE AI systems to enhance identity verifications, at locations such as the Incheon International Airport in South Korea. JT Group, based in Japan, operates a pharmaceutical business and is planning to use our HPE AI systems to support AI model training and simulations to accelerate drug discovery. And we just announced that we will power Scaleway's AI cloud service offering using our HPE AI systems. The new service will make powerful computing accessible to companies to support their various AI workloads and use cases. As we capitalize on the AI growth opportunity, we also see indications of the market recovery in traditional and cloud infrastructure markets. Orders for traditional service grew sequentially and year over year, driven by enterprise public sector and SMB customers in North America and Europe. We are seeing no indication of cannibalization from accelerated computing demand. And revenue grew sequentially as customers transitioned to higher AOP, HPE ProLiant Gen11 servers. Differentiate the customer-centric innovation positions as well to capture this market recovery. For example, our leading HPE GreenLake hybrid cloud is attracting new customers. In the second quarter of fiscal 2024, the number of customer organizations using HP GreenLake increased sequentially by almost 9% to 34,000. And our as-a-service lifetime total contract value grew to more than $15 billion in Q2, with our annualized revenue run rate, or AIR, growing 39% year over year. Demand is increasing for our HP GreenLake on-premise private cloud solutions. The Defense Information Systems Agency, a combat support agency of the United States Department of Defense, selected HPE to develop a distributed hybrid multi-cloud platform prototype on HPE GreenLake as part of an effort to simplify the organization's management of disparate IT infrastructure and resources across public and private clouds. In storage, we accelerated the transition of our portfolio in Q2 to meet the needs of hybrid cloud and AI. Several weeks ago, HPE introduced significant new functionality to our HPE Electra storage offerings. We rounded out our block offering by extending the hybrid capabilities of HPE Electra block storage to AWS, doubling its capacity to address more customers and enhancing its automation capabilities with generative AI. Earlier this quarter, we introduced new HPE GreenLake for file storage capabilities with options specifically targeting the unstructured data demands of AI. We have also added significant specialty sales capacity in recent months. While it takes time to activate new sellers and bring them to full productivity in a market with long sales cycles, we expect increased order-to-revenue conversion in the future. The enhancement to our winning portfolio complemented by a more focused sales force position HP to strengthen the already robust customer adoption of HP Alletra. More than 1,000 new HP Alletra MP systems have been deployed to date, which is the fastest product ramp in the history of our company. In networking, the market remained in transition during the quarter as customers continued to work through their current inventory. As demand in this segment gradually returns, we believe our broad portfolio positions as well. We expect modest sequential network and demand improvement driven by the state and local purchasing season in the United States. We announced significant new innovations during the quarter to align with the HPE's broader AI strategy. These solutions include generative AI capabilities to improve AI ops and Wi-Fi 7 access points that capture edge data for AI inferencing. In addition, last month, we launched new security and AI observability tools to help fight AI cyber risks. And just yesterday, we expanded the most complete private 5G and Wi-Fi portfolio in the market with the launch of HP Aruba Networking Enterprise Private 5G. All of this will be delivered through our HP GreenLake Cloud Platform. Customers are responding to our networking innovation. In the last few months, customers ranging from Houston Airport to Batista Health Group to Mercedes-Benz Stadium to the University of Maryland have turned to HPE to enhance the experience for their visitors, residents, and employees. As we look to our future in networking, we continue to be very enthusiastic about the proposed acquisition of Juniper Networks. We are currently in the regulatory process for this transaction and expect to close by the end of 2024 or early 2025. As I mentioned earlier, we continue to invest in innovation while we drive operational and cost discipline to continue to improve our cost structure. We are focused on reducing complexity in our business processes, as well as implementing automation and AI across the company to enhance customer service, R&D productivity, and team member overall experience. I also want to note that we recently announced we have restructured the sale of our stake in H3C. Since the transaction is large and complex, the required regulatory approvals will take longer than previously anticipated. So we agreed to restructure the sale with UNIS. The updated agreement provides HPE with the opportunity to sell a significant portion of the shares in the coming months. The new payment structure has no impact on the pending Juniper Networks transaction as the structure of the deal financing does not rely on any of the H3C proceeds. Finally, You likely saw that we announced in May that we have agreed to divest our communications technology group to enhance our strategic focus in high growth, high margin parts of the market, including the service provider and enterprise markets. In closing, I want to reiterate that I'm proud of the very solid performance in Q2. It shows the alignment of our strategy and innovation to major market opportunities. We have greater optimism about the second half of the year, leading us to raise our full year revenue and non-gap earnings per share guidance. AI is creating growing demand across our portfolio, and we see significant opportunities across customer and business segments. Our competitive advantages, from deep expertise in standing up AI systems to our differentiated HP GreenLake Cloud to our networking and storage offerings position as well. We have an excellent team, and I'm confident in our ability to continue executing with discipline to take advantage of incredible opportunities presented by this era of innovation. I am looking forward to sharing with you our latest breakthrough innovation and partnerships across AI, hybrid cloud, and networking later this month at HP Discover Las Vegas. We are very excited to be the first corporate keynote at Sphere, and I hope to see many of you there. I would like now to hand it over to Marie, who will talk about the details of our segments and our outlook. Marie, over to you. Thank you, Antonio, and good afternoon, everyone. It's a pleasure to be here with all of you after my first full quarter as HPE's CFO. Over the past three months, I have become even more excited about our opportunities across AI, hybrid cloud, and networking. We remain in the very early days of AI, yet it is already driving strong interest, pipeline, orders, and revenue across our portfolio from servers to storage to services to financing. Our AI system revenue inflected positively in Q2. We are winning deals in the AI market now and are well positioned for additional demand from enterprises and sovereigns in the future. Our differentiation includes decades of liquid cooling expertise and financial results and is a pillar of our strategy to pursue higher growth, higher margin revenues. We are very pleased that we have exceeded our expectations in Q2 across key metrics. We exceeded the midpoint of our revenue guidance by $400 million. Non-GAAP diluted net EPS was above the high end of our range and free cash flow exceeded $600 million. Improving enterprise demand for traditional servers on top of the expected sharp ramp in AI servers drove the outperformance. Our AI orders are healthy. Intelligent Edge is set to grow sequentially beyond Q2 as expected, and AI emerged as a driver of a healthy HPE GreenLake momentum. We are seeing rapid growth in AI system revenue. Overall, I am very pleased with our performance in Q2 and am excited about our continued progress through fiscal 24. Let's take a closer look at the details of the quarter. Revenue grew 4% year over year and 7% quarter over quarter in constant currency to $7.2 billion. This exceeded the midpoint of our prior guidance by approximately $400 million. we have strong momentum in HPE GreenLake. The number of customers that have adopted HPE GreenLake rose 9% sequentially. ARR grew 39% year over year to above $1.5 billion in Q2. Storage and networking are typically the fastest growth elements of ARR and both retain robust growth rates. This quarter, AI was the fastest growth component of AAR. Our software and services mix rose approximately 200 basis points year over year to 67%. AAR is the best indicator of our model transformation to our as-a-service offerings. This growth validates what our customers are telling us, that HPE GreenLake is a key differentiator. We expect HPE GreenLake's value proposition to key customers, including enterprises and sovereigns, to sharpen with the advent of AI. Our Q2 non-gap gross margin was 33.1%, which was down 310 basis points sequentially and year over year, driven by a mixed shift from our higher margin intelligent edge revenue to server revenues. plus an unfavorable mix within hybrid cloud. Our Q2 non-gap operating expenses fell 1.6% year over year, despite our revenue growth of 4%. Our OpEx discipline partially offset lower non-gap gross margins and held the non-gap operating margin decline to 200 basis points sequentially and year over year to 9.5%. The OPEX discipline plus higher revenue drove gap-diluted net EPS of 24 cents and non-gap-diluted net EPS of 42 cents. The latter exceeded the high end of the guidance range on strong revenue and cost discipline. A non-gap-diluted net earnings per share excludes $247 million in net costs, primarily from stock-based compensation expense amortization of intangibles and acquisitions, and other related charges. We are managing the business with focus and discipline and evolving into a simpler, more agile company. We are also investing to capitalize on growth from the interrelated infection points in AI, hybrid cloud, and networking, and to drive structurally higher profitability over time. Let's turn to our segment results. Server revenues were $3.9 billion in the quarter. This was up 16% sequentially and up 18% year over year. Strengths in both AI systems and traditional servers drove the healthy revenue growth. Our cumulative AI system product and service orders since Q1 23 rose approximately $600 million sequentially to $4.6 billion. I am very pleased with our AI system product revenue more than doubled sequentially to over $900 million. This strong revenue growth allowed us to make progress against our backlog, which is now $3.1 billion. Given the growing importance of our services business, we have updated our AI disclosures for this quarter to include services. Services is a small portion of our AI systems metrics at present, though we expect it to become more meaningful over time. Our differentiation with liquid cooling, software, HPE GreenLake, and increasingly services is resonating in the market. We have seen a three-fold increase in our enterprise AI customer base in the past year. Revenue from our traditional server business increased sequentially. We expect this trend to continue. Demand is improving as enterprises digest prior purchases and gain more comfort with the macro outlook. The structural mix shift to higher AUP Gen11 servers is ahead of our expectations, and we are able to pass through rising input costs. We are encouraged that our Gen11 pipeline is starting to include AI inferencing activity and enterprise applications, and we see more evidence of adoption in the enterprise in Q2. Our Q2 operating margin was 11%. This was down 40 basis points sequentially and was in line with the expectations we laid out last quarter for our operating margins near the lower end of our long-term 11% to 13% range. While pricing remains aggressive in the server market, particularly in AI systems, we remain disciplined in cost and price as we pursue profitable growth. Hybrid cloud revenues of $1.3 billion were up 1% sequentially and down 9% year-over-year. We are already seeing some cross-selling benefits of integrating the majority of our HPE GreenLake offering into a single business unit. I mentioned the 39% growth in ARR this quarter. Our traditional storage business was down year-over-year. The business is managing two long-term transitions at once. We talked about our migration to the more software intensive Electra platform. This is reducing current period revenue growth, though locking in future recurring revenue. Storage AAR growth of over 50% year over year offers early confidence into the migration. The second transition is from block storage to file storage driven by AI. While early, this is also on the right trajectory. Our new file offerings plus the Salesforce investment Antonia mentioned tripled our pipeline of file storage deals sequentially in Q2. Our operating margin was 0.8%, which was down 300 basis points sequentially and 110 basis points year-over-year. Reduced revenue scale and an unfavorable mix of third-party product and traditional storage was the largest driver of the sequential change. Intelligent Edge revenues were $1.1 billion. Revenues fell 9% sequentially and 19% year over year. Backlog consumption created difficult compares with both prior periods. Our backlog is now at normal levels. The demand environment remains soft and large enterprises have yet to return to the market in force. We do see some green shoots that give us confidence networking will transition to modest sequential growth beyond Q2, as we had expected. Our channel inventory remains within the normal range. Wi-Fi has grown sequentially for two consecutive quarters. Growth remains strong in software and services. Attach rates and renewals for Aruba Central, SASE, and our AIOps software remain strong. The Intelligent Edge portfolio of subscription revenue grew above 50% year over year. The segment operating margin of 21.8% was down 760 basis points sequentially and 290 basis points year over year. As expected, the lower revenues reduced mix of switching business and the less revenue from backlog were the primary drivers. As we indicated last quarter, we have reset our OpEx plan for the year to account for lower revenue and expect the Intelligent Edge operating margin to be back in the mid-20% range by Q4. Our HPE financial service revenue was up 1% year-over-year and financing volume was $1.7 billion. Our operating margin of 9.3% was up 80 basis points sequentially and 40 basis points year-over-year. our Q2 loss ratio remains steady below 0.5%. These results are what we have come to expect from this high quality, predictable business. However, underneath these steady results, FS is already adapting to drive AI growth across the business. Year to date, nearly half a billion dollars of our 3 billion in financing volume went to AI wins with both cloud and enterprise customers. This illustrates our prior point that AI is driving demand to every one of our businesses. Turning now to cash flow and capital allocation. We generated $1.1 billion in cash flow from operations and $610 million in free cash flow this quarter. HPE typically consumes significant amounts of cash in the first half of the year and then generates cash in the second half. We are ahead of traditional free cash flow patents thus far in fiscal 24, given higher than expected net income in Q2, prepayments for AI systems, and timing of working capital payments. Our cash conversion cycle was negative four days, which is a reduction of 28 days from Q2 23. Our days of inventory and days payable were both higher to support our expected growth in AI system revenue in the second half. We returned $240 million in capital to shareholders in Q2, including $169 million in dividends and $45 million in share repurchases. Our year-to-date capital return is $386 million. Let's turn now to our forward view. We expect a materially stronger second half led by AI systems, traditional servers, and storage, networking, and HPE GreenLake. Let me recap the key drivers that factor into our expectations for Q3 and the full year. For server, we expect improving GPU supply for AI systems and improving demand for traditional servers to drive sequential revenue increases through fiscal year 24. While the rising AI systems mix is a gross margin headwind, we are balancing this with higher margin services revenue, improving scale, and cost discipline. We expect the segment operating margin to be approximately 11% for the fiscal year. For hybrid cloud, we expect slight sequential revenue increases throughout the year. HPE GreenLake growth should continue and traditional storage should improve slightly. We expect operating margin to improve modestly to the mid single digit range through the year as HPE GreenLake deals mature, new products ramp, and our Salesforce optimization gathers momentum. For Intelligent Edge, we anticipate slight sequential growth in Q3 and Q4, driven primarily by seasonal education spending rather than improving markets. We continue to expect our cost reduction efforts to materialize in the second half and our full-year operating margin to be in the mid-20% range. With that context, let me now turn to our outlook. For Q3, we expect revenues in the range of $7.4 to $7.8 billion. We expect GAAP diluted net EPS to be between $0.29 and $0.34 and non-GAAP diluted net EPS between $0.43 and $0.48. For fiscal year 24, we now expect constant currency revenue growth of 1% to 3%, which is up from our prior 0% to 2% range. We reiterate our non-GAAP operating profit growth guidance of 0% to 2%. We are reducing our gap-diluted net EPS guidance by 20 cents to $1.61 to $1.71 to incorporate the recent updates to our H3C proceeds. We are raising our non-gap-diluted net EPS guidance up 3 cents to $1.85 to $1.95. This incremental 3 cents or 6 cents annualized reflects the contribution from the retained portion of our H3C stake. We are also increasingly comfortable with the high end of the non-GAAP diluted net EPS range, given our OINE and operational improvement. We are excluding from our non-GAAP results the gain on sale from our H3C and CTG divestments. This year's mixed shift from networking to AI systems should weigh on our gross margins. We expect the fiscal 24 non-GAAP gross margin to be below our full-year expectation of 35% from our analyst day. To balance the mixed shift, we are driving further simplicity and efficiency across the business. We are accelerating our generative AI capabilities, such as implementing HPE-specific large language models and chatbots for our sales and service representatives. As I mentioned last quarter, prudent cost management simplified processes, and disciplined execution across cycles are key tenets of our long-term journey towards higher margins. These cost actions will be evident in financial results in the second half of fiscal 24. We now expect fiscal year 24 OPEX to be down modestly from fiscal 23 OPEX. Our prior view was flat to down. This includes a sequential increase in Q3 for marketing before a sequentially lower Q4, which will serve us well heading into fiscal 25. We expect our fiscal 24 operating margin to be flattish year over year. We now expect OINE to be less of a headwind this year. We anticipate a $150 million headwind versus our prior expectation of a $200 to $250 million headwind given a one-time benefit in Q2 and the retained portion of a H3C stake. We expect the effect of currency to be immaterial. Our strong first-half free cash flow increases our confidence that we will deliver at least $1.9 billion in fiscal year 2024. We expect significantly stronger free cash flow in the second half of the year, led by higher earnings given our ramp in AI systems. This does not include the $2.1 billion that we expect to receive from Unisplendor this fiscal year as a result of our recently restructured agreements to sell our stake in H3C. We expect working capital to be neutral to free cash flow, as we expect declines in inventory to balance declines in accounts payable. We remain committed in the long term to our balanced capital allocation framework, including our target of returning 65% to 75% of free cash flow to shareholders. In the near term, we expect to continue share repurchases at a pace in line with Q2 as we prudently manage our balance sheet ahead of the anticipated receipt of the H3C proceeds and the Juniper transaction closing. The proposed Juniper deal remains on track to close in late 2024 or early 2025 as planned. We remain committed to our dividend and to our investment grade rating. To conclude, our solid Q2 results illustrate how comprehensively AI is affecting our portfolio. We are capturing profitable growth opportunities in the AI market. We are excited for Discover and look forward to seeing many of you at our IR Summit. I'll open it up now for your questions. We will now begin the question and answer session. To ask a question, you may press star, then 1 on your touchtone phone. If you are using a speakerphone, please pick up your handset before pressing the keys. To withdraw your question, please press star, then 2. We also request that you only ask one question. The first question is from Amit Daryanati with Evercore. Please go ahead. Thanks a lot and congrats on a nice sprint. I guess my question is really on the AI system side. You folks have really good revenue performance here. I think business pretty much doubled sequentially. I'm hoping you could spend some time talking about How should we think about margins on the AI side versus maybe segment averages? Because your margins appear to be holding up a lot better versus they have done at Dell or Supermicro, for example. So I'd love to just understand how do we think about AI system margins versus corporate averages? And if you just touch on what do you think differentiates your AI solutions versus companies like Supermicro or Dell that would be super helpful? Thank you. Hey Amit, good afternoon. It's Marie and happy to take the question. And look, honestly, you know, we shipped 900 million of AI revenue in the quarter. And I think as you saw, you know, our margin rate on our service segment from an operating profit perspective was 11%. So look, honestly, as a CFO, very pleased. That's what we guided and that's what we achieved and that's what we've guided for the second half of the year. In terms of what the puts and takes and the headwinds and tailwinds, let me give you some color around it. So from a headwinds perspective, obviously we're dealing with a tougher inflationary commodity market, particularly even in the second half. And we also see, as you saw in the quarter, a greater mix of AI servers. actually in our overall server mix. And as you know and you've heard, it's a pretty competitive market out there, I might add, too. But clearly, we're managing it very well. And I'd say what's benefiting us is a couple of really important tailwinds. One is what we're seeing in terms of the Gen 11 transition. That part of the business brings a higher AUP. And then also, frankly, Amit, it's the work we're doing around cost. So as a result, I think this really illustrates that we are very disciplined around both price, and cost, and frankly, it's part of our strategy to drive profitable growth. So, pleased with the results, and that's how we're guiding the back half of the year, Ahmed. So, Ahmed, on the differentiation, I will summarize this on four key elements. One is our ability to deliver and run systems at scale, so AI systems at scale. That's a unique expertise, and we have decades of experience. Number two is our infrastructure cooling intellectual property. You know, we actually have all the IP necessary to cool systems in three different ways, for that matter. Our manufacturing footprint, which is very unique. We have one of the largest water-cool manufacturing footprints in the world, with two very important locations in the U.S. and in Europe, which are close to customers. And then, last but not least, the services. What I think people are coming to realize that running the system of scale requires unique services capabilities. And that's why, with Marie, we started showing you what the services pull-through is, which is also, over time, a lever to improve the gross margin in this business. And we cover all aspects, from day zero, which is consulting, to day one, which is advisory and professional services design and build, and then day two, which is the running part with our operational services side, and deep expertise when it comes down to this system of scale, including direct liquid cooling. All those four key elements are a big differentiation for us. Thank you, Amit. Gary, maybe the next question? And the next question is from Aaron Rakers with Wells Fargo. Please go ahead. Yeah, thanks for taking the question. I guess sticking on the AI topic, if I could first ask, You know, when you referenced the AI enterprise customers starting to show up, and I think the comment in the conference call was it's now north of 15% of your AI orders. Can you give a little bit more context to that? What has that been over the last couple of quarters? I'm just trying to think about the trajectory of that. And, Antonio, on the liquid cooling side, you know, as we and investors think about Blackwell product cycle from NVIDIA, I'm curious, can you be a little bit more specific of exactly where, from a technology perspective, you differentiate at liquid cooling? Is there something unique that HP does within the 300 patents that you would want to highlight for us as sustainably differentiated? Thank you. Yeah, thanks, Aaron. I think it's fair to say that the enterprise demand has started to pick in Q1 and really accelerating Q2 early on. If you go back to the Q1 2023 all the way to call it calendar 2023, a lot of demand came from the model builders, the service providers, and hyperscalers, and you see the reference to our partner Microsoft. But as I think about that, I think three segments of the market. I think about that segment which is driving a lot of demand for a lot of gpus and accelerated compute in general the second segment is sovereign clouds and that starts to pick up now uh and that's think about tens of customers around the globe you know because obviously our countries and then there is enterprise customers which will be thousands of customers over time so uh today we are very pleased with the momentum in enterprise ai a lot of conversations are happening i was in europe uh the last two weeks and i was in london i was in paris i was in madrid all of them want to adopt ai and i think they are attracted to hpe because of the trust the quality and ability to deliver a simplified experience to our hp green lake platform as for the differentiation you know HP has three different ways to cool systems. So one is the traditional way, which is called the liquid-to-air cooling. Think about that, you know, basically running water supply in chill locations where basically, you know, cools the air around the systems. Everybody has known that for a long time. The second is what most of the industry is doing today, which is what I call 70% direct liquid cooling or hybrid liquid cooling. um you know those companies still use fans to cool aspects of the systems some of our competitors will talk about the red liquid cooling but that's exactly what they're doing they are doing only a hybrid direct liquid cooling and hpe has uni and by the way in that environment we have 10 systems already in market today that we are shipping and configuring for customers And then we have what I call 100% direct liquid cooling. And this is a unique differentiation HP has because we have been doing 100% direct liquid cooling for a long time. And today there are six systems in deployment, and three of them are for generative AI. And as we go to the next generation, of the silicon, and you talk about Blackwell, when you go to the B200, that will require 100% direct liquid cooling. And that's unique opportunity for us because you need not only the IP and the capabilities to cool the infrastructure, but also the manufacturing side. And that's why I said early on to the previous call that HPE has one of the largest water cool manufacturing capabilities. so that's what really differentiated us and even on the hybrid you know a way to cool the system hpe is not using off-the-shelf solution we use what we call an arc which stands for adaptive rack cooling system is a unique design and the good news is that we can actually collocate in the same data center and in the same aisle uh direct liquid cooling and air cool systems, which is unique because customers don't want to retrofit data centers. So that's the opportunity. Aaron, thanks very much. Gary? The next question is from Mayda Marshall with Morgan Stanley. Please go ahead. Hi, this is Mary on for Mayda. I just had a question for you on Intelligent Edge. Where are you in the Intelligent Edge inventory digestion, and when do you expect to emerge from it? Yes, good afternoon. And in terms of where we're at Intelligent Edge, I think as I commented in my prepared remarks, you know, we saw Q2 as being the trough period and we've been transitioning through that throughout the quarter. And if you look at the market and where it's at right now, I'd say that our channel inventory right now is in really good shape. And we did mention in the guide that we do expect a modest sequential improvement in networking in the back half of the year. Yeah, and I will say, in addition to what Marie said, what I'm really excited is that we see interesting areas of growth happening now. If you go back to Mobile World Congress and you see even announcements like we made yesterday, the enterprise private 5G is picking up significant momentum. Of my almost 40 meetings I had in Barcelona, more than half were about enterprise private 5G. And so yesterday... we announced the most complete enterprise private 5G on the back of the AutoNet acquisition. Thanks very much, Mary. Gary? The next question is from Tony Sakonagi with Bernstein. Please go ahead. Yes, good afternoon, and thank you for taking my question. I just wanted to follow up on the guidance. You talked about enthusiasm for the second half, but you beat revenues this quarter relative to your expectations by 400 million. And by guiding up an additional percent, you're actually only guiding up the full year by 300 million. So I'm wondering, are you just being conservative given the commentary around enthusiasm and forces at work in the second half or, How do we reconcile that discrepancy? And then also just on AI servers for the second half, I think you talked about six to 12-week lead time. So if you have $3 billion in backlog and lead times are six to 12 weeks, why can't you deliver $3 billion in AI systems like next quarter or certainly in the second half? Thank you. Hi Tony, good afternoon. So this is Maria. I'm going to take the first question just on the guide. So let me just clarify the guidance in terms of how we put it together. So we raised the guide to $185 to $195 and that actually was the pass-through on that 19% stake in H3C. So we actually put $0.03 related to the 19% stake. What I did point to, though, Tony, is I pointed to the higher end of the range. So that's really what's giving us confidence, you know, based on the increase that we made on revenue. So you've seen that higher top line and then also the confidence I got around just the cost discipline. So you've seen that just in the last couple of quarters where we've had a really strong scrutiny and focus around OPEX. And plus, we did have some favorability in OINE this quarter. But albeit, that was actually just a one-timer. So I just want to make that point of clarification. So overall, Tony, keeping the guide at 185 to 195, but really pointing to the higher end of the guide in terms of just the confidence that you articulated. So I'll turn it over to Antonio to cover this section. Yeah, Tony, I think there is an opportunity to potentially exceed that. I think the limiting factor is not the supply, to be honest with you, is the availability of data center space. I made this comment in Q1, if you recall, data center space and power in Cooley. and so some you know we're working with customers to time everything correctly you know six to 12 weeks think about it you know maybe less than a quarter but then you have to go and install it and you know there is a a nice percentage of our deals in generative ai which are all actually green lake and so while we can recognize the revenue upfront. We are deferring all the services piece of it. So it really is going to come down to the timing of the data center and the power and cooling. And if that all aligns correctly, then we may have an opportunity to do better. But we felt proven to this point in time to keep it the way it is and raising by 1%. Tony, thanks very much. Gary? The next question is from Samekh Chatterjee with JP Morgan. Please go ahead. Hey, thanks for the question. This is Joe Cardoso on for Samekh. So maybe just following up on the AI questions, you know, you're seeing a sequential decline in the AI backlog this quarter, admittedly off of a very robust revenue quarter. But maybe you can just discuss the pipeline you're seeing. And, you know, if sitting here, like what are some of the potentates that investors should be considering when seeing the sequential decline in backlog, despite what appears to be a strong underlying demand environment overall? Thanks. Sure. Thank you. Yes, our backlog was slightly down quarter over quarter. also was based on the demand we took in and also the fact that we converted more. I think you have to realize some of these deals, particularly large deals, take time and are a little bit lumpy. Some of them have to go through the financing side. And so we feel good about where we are today. But in terms of the pipelines, think about multiples of the current backlog, multiples of the current backlog. So as we go through the next weeks and quarters here, We feel very confident in our ability to capture that AI for all the reasons I described before, and also the ability to close these deals, as some of them may include, by the way, the need to provide data center space as well, because we are not just building the system. And these are all generative AI systems, by the way, all of them, that we also need to run it for customers. Thanks very much, Joe. Gary? The next question is from Simon Leopold with Raymond James. Please go ahead. Hi, this is Victor Chew in for Simon. The doubling the AI systems revenue is pretty sharp inflection this quarter. Can you just tell us how much of the increase was driven by allocation improvement versus ability to ship orders and kind of just help us understand the dynamic there a little bit? No, I don't think he has to do anything with that location. I read all this thing about location. We have fantastic partnership with NVIDIA. It's about lead times in the general, you know, H100, which obviously NVIDIA made significant improvements on their own. And then obviously as we start ramping our manufacturing processes, we actually become better and better at that revenue conversion, you know. And I would say I want to thank my team because my team did a fantastic job and we feel good about as we go forward. So it's a combination of multiple things. Better lead times on supply. We feel pretty good about the ability to deliver systems six to 12 weeks, to Tony's question. And some of them are straightforward. It's just shipments. And some are with RHP GreenLake offering wrapped around. Thanks very much, Victor. Gary? The next question is from Ruflu Bhattacharya with Bank of America. Please go ahead. All right, thanks for taking my questions. That's what we're filling in for Wamsi today. Can you talk about how much of the GreenLake revenue and ARR growth came from AI? And Antonio, do you think that having GreenLake is helping you sell AI systems? And I also wanted to clarify, Antonio, you talked about sovereign AI. Can you talk about what innings you're in and are there specific requirements of sovereign AI where you think HP is well positioned to satisfy? Hey Rupert, it's Mary. Look forward to seeing you tomorrow. So in terms of your question around just AAR and AI, actually, you know, it was the fastest growth element of AAR and Q2, followed by storage and networking. So I think, as I said in my prepared remarks, we're starting to see AI just sort of, you know, move through our entire portfolio. So pleased with the progress that we had this quarter. I'll turn it over to Antonio to add some more context. Yeah, you know, on the second part of the question, you know, I think we are early in this point in time, you know, I think there is more to be seen. And I want to make sure I captured exactly what you said. Can you repeat the last part because we were a little bit breaking? Yeah, I just wanted to ask about sovereign AI, you know, and are there specific requirements that you can satisfy? Yeah, so on Sovereign AI, I said it's early, early on. I think there is a lot of engagements right now happening at the country level. The good news, we have very good reach across the board. And it's a combination of both. There's a combination of providing what I call generative AI locations where customers, enterprise customers, can get access to a sovereign cloud that the government may be helping funding at the same time. And the other one is what I call supercomputing power, right, itself. And so the two are very well aligned to the sovereign AI opportunities. And that's why I'm excited because HPE already provides you know, to allow the sovereign governments supercomputing. So now we can extend intergenerative AI. If you think about the example of the UK, Bristol, is a generative AI system that the UK is funding as a part of the Bristol University that eventually is going to be open to startups and enterprises in the UK to either train models or do other type of research. And that's what we see. Okay, thanks very much, Rublu. Derek, we have two more questions, please. And the next question is from Ananda Barua with Loop Capital. Please go ahead. Hey, yeah, good afternoon, guys. Really appreciate you taking the question. Just a quick clarification and a quick question, Antonio. Did you say that the last 12 months AI growth was driven by service providers and was it mobile, you said? And then the question is that What's a good way to think about cloud, your GenAI cloud scale opportunity, hyperscalers and tier twos going forward? Thanks a lot. Yeah, no, thank you. I said, you know, the segment where we have seen obviously the vast majority of action and demand is the model, model builders. Those are the companies that build large and small language models. Obviously, you saw our comments about our partner with Microsoft and the extension of their capacity to open AI. That's an example of a mobile builder. But also, there are other service providers. And in fact, in my remarks, I mentioned Scaleway, which is a French service provider that provides the capacity for the local French mobile builders. In fact, there is a very vibrant ecosystem in France about building AI models that will use that capacity to train the models. That's what I refer to at this point in time. And that's what we see. That's what we see. So we are very interested in not just the model builders, but tier two, tier three, which also is going to be a big driver, but understanding that enterprise ultimately what the action is going to happen in terms of fine-tuning and deploying these AI models over time. Okay. Thank you very much, Ananda. And last question, Gary. And the last question is from Lou Michioshia with Diawa. Please go ahead. Hey, thanks for getting me in. So my question is really about GPU or accelerated diversification. Obviously, AMD and Intel and others are starting to come out. So as you think about calendar 2024, what do you think that your system will be for this and what do you think demand will be? And then maybe continue that into 2025? Yeah, I mean, listen, I'm very pragmatic about these things. Today, in generative AI, the market leader is NVIDIA. And that's where we have aligned our strategy. That's where we have aligned our offerings. And as I made my remark earlier, We have 10 systems already in the mixed cooling environment and six systems or six offers also in the direct liquid cooling environment. So we are aligning with NVIDIA today. And that's why you're going to see Discover Jensen coming on stage with me to talk about what we're doing together. Now, when you go into the sovereign space where there may be some components of supercomputing down the road, Obviously, you know, they designed their own systems with our help, and that will be a mixed environment. But just in the last month or so, we opened a new system in the Los Alamos laboratory, which was actually an NVIDIA system with HPE, and it's direct liquid cooled, so we are clear about that. But then there are also systems that will come in 2025 that may have different type of accelerators. Over time, we're going to be time to market, but right now we are aligned to NVIDIA and that's what we're doing. And that's why I think it will be a great opportunity for you to join us at HP Discover because you can see everything we talk today on the floor. Every system I just refer to my slides, every comment I made in my answers to the questions, you can come and see it. These are systems and IP that we are shipping today. And you're going to see our time to market with this silicon in addition to all the services in HP GreenLake. So it's going to be an amazing opportunity. Also, because we are doing the keynote at Sphere, we're going to have probably inside the Sphere more than 17,000 customers and partners joining us. So I know we don't have no more time for questions, but I will say thank you for joining today. As a recap, the quarter was very solid. Our AI system revenue more than doubled to $900 million, allowing us to obviously exceed our revenue and ungap earnings per share guidance. Because the demand in AI is strong, we have a multiple of the backlog in our pipeline, and some aspect of the traditional infrastructure market is recovering. plus our discipline execution on pricing and cost, we are raising both the revenue and EPS guidance. And on the revenue, there could be something more, obviously, but it's depending on some of the timing. And then, obviously, on the EPS, we are comfortable with a higher end of the range, as Marie said. So, again, we are very pleased. We feel the second half is going to set up really well. And then, obviously, we are looking forward to see many of you at HP Discover in just less than two weeks. Thank you for your time today. Ladies and gentlemen, this concludes our call for today. Thank you.